/// BERK Scientific Computing - Matrix Operations
///
/// Bu demo BERK'in bilimsel hesaplama gÃ¼cÃ¼nÃ¼ gÃ¶sterir:
/// - High-performance matrix multiplication
/// - Region memory ile sÄ±fÄ±r allocation overhead
/// - SIMD optimizasyonlarÄ±
/// - NumPy/MATLAB seviyesi performans

kullan std::linalg
kullan std::time

/// Matrix multiplication - Naive implementation
fonksiyon matrix_multiply_naive(
    a: &[[f64]], 
    b: &[[f64]]
) -> [[f64]]
yap
    deÄŸiÅŸken rows_a = a.len()
    deÄŸiÅŸken cols_a = a[0].len()
    deÄŸiÅŸken cols_b = b[0].len()
    
    deÄŸiÅŸken result = yeni [[f64; cols_b]; rows_a]
    
    iÃ§in i iÃ§inde 0..rows_a
        iÃ§in j iÃ§inde 0..cols_b
            deÄŸiÅŸken sum = 0.0
            iÃ§in k iÃ§inde 0..cols_a
                sum += a[i][k] * b[k][j]
            son
            result[i][j] = sum
        son
    son
    
    dÃ¶n result
son

/// Matrix multiplication - Optimized with SIMD
fonksiyon matrix_multiply_simd(
    a: &[[f64]], 
    b: &[[f64]]
) -> [[f64]]
yap
    // BERK'in optimize edilmiÅŸ linalg kÃ¼tÃ¼phanesi
    dÃ¶n linalg::matmul(a, b)
son

/// Matrix operations benchmark
fonksiyon benchmark_matrix_operations()
yap
    yaz("\n=== Matrix Operations Benchmark ===\n")
    
    sabit SIZE = 500
    
    yaz("Matrix boyutu: ", SIZE, "x", SIZE)
    yaz("Toplam iÅŸlem sayÄ±sÄ±: ", SIZE * SIZE * SIZE, "\n")
    
    // Test matrix'leri oluÅŸtur
    bÃ¶lge matrix_gen yap
        deÄŸiÅŸken a = yeni [[f64; SIZE]; SIZE]
        deÄŸiÅŸken b = yeni [[f64; SIZE]; SIZE]
        
        // Initialize with random values
        iÃ§in i iÃ§inde 0..SIZE
            iÃ§in j iÃ§inde 0..SIZE
                a[i][j] = (i * SIZE + j) as f64 * 0.01
                b[i][j] = (j * SIZE + i) as f64 * 0.01
            son
        son
        
        // Naive implementation
        yaz("1ï¸âƒ£  Naive matrix multiply...")
        deÄŸiÅŸken naive_start = time::now()
        deÄŸiÅŸken result_naive = matrix_multiply_naive(&a, &b)
        deÄŸiÅŸken naive_time = time::duration_ms(time::now() - naive_start)
        yaz("   âœ… TamamlandÄ±: ", naive_time, " ms\n")
        
        // SIMD optimized
        yaz("2ï¸âƒ£  SIMD optimized multiply...")
        deÄŸiÅŸken simd_start = time::now()
        deÄŸiÅŸken result_simd = matrix_multiply_simd(&a, &b)
        deÄŸiÅŸken simd_time = time::duration_ms(time::now() - simd_start)
        yaz("   âœ… TamamlandÄ±: ", simd_time, " ms\n")
        
        // Verify results match
        deÄŸiÅŸken match_ok = linalg::compare_matrices(&result_naive, &result_simd, 1e-10)
        yaz("SonuÃ§lar eÅŸleÅŸiyor: ", eÄŸer match_ok "âœ… EVET" deÄŸilse "âŒ HAYIR")
        
        yaz("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        yaz("â•‘  Naive:         ", naive_time, " ms")
        yaz("â•‘  SIMD:          ", simd_time, " ms")
        yaz("â•‘  Speedup:       ", naive_time / simd_time, "x")
        yaz("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    son  // Matrix'ler otomatik temizlenir - region memory!
son

/// LU Decomposition - DoÄŸrusal denklem Ã§Ã¶zÃ¼mÃ¼
fonksiyon lu_decomposition_example()
yap
    yaz("\n=== LU Decomposition ===\n")
    
    // Ax = b sistemini Ã§Ã¶z
    deÄŸiÅŸken a = [[4.0, 3.0], [6.0, 3.0]]
    deÄŸiÅŸken b = [10.0, 12.0]
    
    yaz("Denklem sistemi: Ax = b")
    yaz("A = ", a)
    yaz("b = ", b)
    
    // LU decomposition ile Ã§Ã¶z
    deÄŸiÅŸken x = linalg::solve_lu(&a, &b)
    
    yaz("\nÃ‡Ã¶zÃ¼m: x = ", x)
    
    // Verify: Ax = b
    deÄŸiÅŸken result = linalg::matvec(&a, &x)
    yaz("DoÄŸrulama: Ax = ", result)
    yaz("Beklenen:  b = ", b)
son

/// Eigenvalue decomposition
fonksiyon eigenvalue_example()
yap
    yaz("\n=== Eigenvalue Decomposition ===\n")
    
    // Symmetric matrix
    deÄŸiÅŸken matrix = [
        [4.0, 1.0, 0.0],
        [1.0, 3.0, 1.0],
        [0.0, 1.0, 2.0]
    ]
    
    yaz("Matrix:")
    linalg::print_matrix(&matrix)
    
    deÄŸiÅŸken (eigenvalues, eigenvectors) = linalg::eigen_symmetric(&matrix)
    
    yaz("\nEigenvalues: ", eigenvalues)
    yaz("\nEigenvectors:")
    linalg::print_matrix(&eigenvectors)
son

/// QR Decomposition
fonksiyon qr_decomposition_example()
yap
    yaz("\n=== QR Decomposition ===\n")
    
    deÄŸiÅŸken matrix = [
        [1.0, 2.0, 3.0],
        [4.0, 5.0, 6.0],
        [7.0, 8.0, 9.0]
    ]
    
    yaz("Matrix A:")
    linalg::print_matrix(&matrix)
    
    deÄŸiÅŸken (q, r) = linalg::qr_decompose(&matrix)
    
    yaz("\nQ (Orthogonal):")
    linalg::print_matrix(&q)
    
    yaz("\nR (Upper triangular):")
    linalg::print_matrix(&r)
    
    // Verify: A = QR
    deÄŸiÅŸken reconstructed = linalg::matmul(&q, &r)
    yaz("\nQR = ")
    linalg::print_matrix(&reconstructed)
son

/// Singular Value Decomposition (SVD)
fonksiyon svd_example()
yap
    yaz("\n=== Singular Value Decomposition ===\n")
    
    deÄŸiÅŸken matrix = [
        [1.0, 0.0, 0.0, 0.0, 2.0],
        [0.0, 0.0, 3.0, 0.0, 0.0],
        [0.0, 0.0, 0.0, 0.0, 0.0],
        [0.0, 4.0, 0.0, 0.0, 0.0]
    ]
    
    yaz("Matrix A (4x5):")
    linalg::print_matrix(&matrix)
    
    deÄŸiÅŸken (u, s, vt) = linalg::svd(&matrix)
    
    yaz("\nSingular values: ", s)
    
    // Rank calculation
    deÄŸiÅŸken rank = linalg::rank_from_svd(&s, 1e-10)
    yaz("Matrix rank: ", rank)
son

/// Linear regression
fonksiyon linear_regression_example()
yap
    yaz("\n=== Linear Regression ===\n")
    
    // Training data: y = 2x + 3 + noise
    deÄŸiÅŸken x_data = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]
    deÄŸiÅŸken y_data = [5.1, 7.2, 9.0, 10.8, 12.9, 15.1, 17.2, 19.0, 20.9, 23.1]
    
    // Fit: y = ax + b
    deÄŸiÅŸken (a, b) = linalg::linear_fit(&x_data, &y_data)
    
    yaz("Fitted model: y = ", a, "x + ", b)
    yaz("(GerÃ§ek: y = 2x + 3)")
    
    // R-squared
    deÄŸiÅŸken r_squared = linalg::r_squared(&x_data, &y_data, a, b)
    yaz("RÂ² = ", r_squared)
son

/// Performance comparison with other languages
fonksiyon benchmark_comparison()
yap
    yaz("\n=== Performance Comparison ===\n")
    
    sabit SIZE = 1000
    sabit ITERATIONS = 10
    
    yaz("Test: ", SIZE, "x", SIZE, " matrix multiply, ", ITERATIONS, " iterations\n")
    
    bÃ¶lge benchmark_region yap
        deÄŸiÅŸken total_time = 0.0
        
        iÃ§in _ iÃ§inde 0..ITERATIONS
            deÄŸiÅŸken a = linalg::random_matrix(SIZE, SIZE)
            deÄŸiÅŸken b = linalg::random_matrix(SIZE, SIZE)
            
            deÄŸiÅŸken start = time::now()
            deÄŸiÅŸken result = linalg::matmul(&a, &b)
            total_time += time::duration_ms(time::now() - start)
        son
        
        deÄŸiÅŸken avg_time = total_time / ITERATIONS as f64
        deÄŸiÅŸken gflops = (2.0 * SIZE * SIZE * SIZE as f64) / (avg_time * 1e6)
        
        yaz("BERK Average: ", avg_time, " ms")
        yaz("Performance: ", gflops, " GFLOPS")
        
        yaz("\nğŸ“Š Typical Benchmarks (1000x1000):")
        yaz("   Python NumPy:  ~100 ms")
        yaz("   MATLAB:        ~80 ms")
        yaz("   Julia:         ~50 ms")
        yaz("   C++ Eigen:     ~45 ms")
        yaz("   Rust nalgebra: ~40 ms")
        yaz("   BERK:          ~", avg_time, " ms")
    son
son

/// Ana fonksiyon
fonksiyon ana() -> tamsayÄ±
yap
    yaz("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    yaz("â•‘  BERK Scientific Computing Showcase              â•‘")
    yaz("â•‘  Linear Algebra & Matrix Operations              â•‘")
    yaz("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    yaz("ğŸ”¬ Features:")
    yaz("   â€¢ High-performance matrix operations")
    yaz("   â€¢ SIMD optimizations")
    yaz("   â€¢ Region memory for zero-overhead")
    yaz("   â€¢ NumPy/MATLAB level API")
    yaz("   â€¢ Production-ready algorithms\n")
    
    // Run demos
    benchmark_matrix_operations()
    lu_decomposition_example()
    eigenvalue_example()
    qr_decomposition_example()
    svd_example()
    linear_regression_example()
    benchmark_comparison()
    
    yaz("\nğŸ’¡ Use Cases:")
    yaz("   â€¢ Machine Learning (model training)")
    yaz("   â€¢ Computer Vision (image processing)")
    yaz("   â€¢ Physics Simulations (numerical methods)")
    yaz("   â€¢ Financial Modeling (portfolio optimization)")
    yaz("   â€¢ Engineering Analysis (FEA/CFD)")
    
    yaz("\nğŸ¯ BERK vs Alternatives:")
    yaz("   NumPy:     High-level API, Python overhead")
    yaz("   MATLAB:    Easy to use, proprietary, slow")
    yaz("   Julia:     Fast, but JIT compilation")
    yaz("   C++ Eigen: Fast, complex syntax")
    yaz("   BERK:      Fast + Safe + Easy! ğŸš€")
    
    dÃ¶n 0
son
